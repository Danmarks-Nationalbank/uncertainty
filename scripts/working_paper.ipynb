{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty and the real economy - Notebook\n",
    "\n",
    "This code recreates the uncertainty indices used in Bess et al (2020). The authors would like to thank Rastin Matin for his code relating to the LDA model. If you use this code, please cite:\n",
    "\n",
    "Bess, M., Grenestam, E., Pedersen, J. and Tang-Andersen Martinello, A. (2020). [Uncertainty and the real economy: Evidence from Denmark.](https://www.nationalbanken.dk/en/publications/Pages/2020/11/Working-Paper-Uncertainty-and-the-real-economy-Evidence-from-Denmark.aspx) Working paper 165, Danmarks Nationalbank. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indices\n",
    "The block below recreates the indices used in the paper. The output is exported as a csv to data/indices (default). All paths can be set by the user in `input_params.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fui.cluster import ClusterTree\n",
    "import lemmy\n",
    "from src.fui.lda import LDA\n",
    "from src.fui.utils import main_directory, dump_pickle, dump_csv, params\n",
    "from src.fui.ldatools import preprocess, optimize_topics, create_dictionary, merge_documents_and_topics\n",
    "from src.fui.ldatools import jsd_measure, create_corpus, save_models, load_model, print_topics, parse_topic_labels\n",
    "from src.fui.indices import LDAIndexer, BloomIndexer, uncertainty_count\n",
    "from src.fui.preprocessing import parse_for_lda, load_parsed_data\n",
    "import pandas as pd\n",
    "\n",
    "# Parse news articles and save to HDF5\n",
    "parse_for_lda()\n",
    "\n",
    "# Count uncerainty words in parsed articles\n",
    "uncertainty_count()\n",
    "\n",
    "# Import Danish lemmatizer\n",
    "lemmatizer = lemmy.load(\"da\")\n",
    "\n",
    "# Create a dictionary and BoW corpus\n",
    "my_lda = LDA(lemmatizer, test_share=0.0, test=False)\n",
    "create_dictionary(my_lda, load_bigrams=True)\n",
    "create_corpus(my_lda)\n",
    "\n",
    "# Train the LDA model\n",
    "my_lda.lda_models, coherence_scores = optimize_topics(lda_instance, topics_to_optimize=90, plot=False)\n",
    "save_models(my_lda, params)\n",
    "\n",
    "# Export top words to table (see table A1)\n",
    "labels = parse_topic_labels('labels', 90)\n",
    "word_list = print_topics(my_lda, topn=30, unique_sort=False)\n",
    "df = pd.DataFrame(word_list)\n",
    "for col in df.columns:\n",
    "     df.rename(columns={col:labels[str(col)]}, inplace=True)\n",
    "dft = df.transpose()\n",
    "dft = dft.reset_index()\n",
    "dft['text'] = dft.iloc[:,1:20].apply(lambda x: ', '.join(x), axis=1)\n",
    "latex = dft.to_latex(\"top_words_table.tex\", columns=['index', 'text'])\n",
    "\n",
    "# Get topics from articles and save to HDF5\n",
    "merge_documents_and_topics(lda_instance)\n",
    "\n",
    "# Build main index\n",
    "main_idx = LDAIndexer(name='ep_all')\n",
    "idx = main_idx.build(num_topics=num_topics,topics=['EP'],topic_thold=0.5,frq='Q')\n",
    "\n",
    "# Plot index (see figure 1)\n",
    "main_idx.plot_index(plot_bloom=True, plot_vix=True)\n",
    "\n",
    "# Build the broad index\n",
    "broad_idx = LDAIndexer(name='broad')\n",
    "broad_idx.build(num_topics=num_topics,topics=['broad'],topic_thold=0.5,frq='Q')\n",
    "\n",
    "# Build our Danish version of the Baker et al. (2016) index\n",
    "bloom_idx = BloomIndexer(name='bloom')\n",
    "bloom_idx.build(logic='EandPandU', bloom_dict_name='bloom', extend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n",
    "\n",
    "## Figure 2\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_long = pd.melt(idx.reset_index(), id_vars='date')\n",
    "df_top = df_long.groupby('date').apply(lambda df : df.nlargest(4, 'value'))\n",
    "bottom = (df.iloc[:,1:].shape[1]-3)\n",
    "df_bottom = df_long.groupby('date').apply(lambda df : df.nsmallest(bottom, 'value').sum())\n",
    "df_top = df_top.pivot(index='date', columns='variable', values='value')\n",
    "\n",
    "df_top = df_top.drop(['idx'], axis=1)\n",
    "df_top.index = df_top.index.strftime('%Y-%m')\n",
    "df_top = df_top*1000\n",
    "\n",
    "cols = df_top.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "\n",
    "df_top = df_top[cols]\n",
    "\n",
    "label_path = os.path.join(params().paths['topic_labels'],\n",
    "                          'labels' + str(90) + '.json')\n",
    "with codecs.open(label_path, 'r', encoding='utf-8-sig') as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "nb_colors = ['#017bd1','#92229c','#c43d21','#df9337','#afd247','#86bff4','#caa8e5','#eeb7ba','#666666','#f4d495','#d5eb90','#c1c1c2', \"#8cffda\", \"#b89e97\", \"#91c499\", \"#ffa987\", \"#b5d99c\"]\n",
    "\n",
    "df_top.plot.bar(stacked=True, figsize=(15,7), color=nb_colors, align='center', width=0.7)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels([t if not i%5 else \"\" for i,t in enumerate(ax.get_xticklabels())])\n",
    "h, l = ax.get_legend_handles_labels()\n",
    "ax.legend([labels[str(x)] for x in l], loc='upper center', bbox_to_anchor=(0.5, -0.19),\n",
    "          fancybox=True, shadow=False, ncol=5)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.set_ylabel(\"Raw index value\", fontsize='large')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "label_path = os.path.join(params().paths['topic_labels'], 'labels90.json')\n",
    "with codecs.open(label_path, 'r', encoding='utf-8-sig') as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "dft=idx.drop(columns = ['idx'], axis=1).transpose()\n",
    "dft.columns = dft.columns.strftime('%Y-%m')\n",
    "\n",
    "nbcm = LinearSegmentedColormap.from_list(\n",
    "        'nbcm', [(0/255,123/255,209/255),  (244/255,212/255,149/255), (196/255,61/255,33/255)], N=200)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,8))\n",
    "\n",
    "ax = sns.heatmap(dft, cmap=nbcm, linewidths=0, annot=False, xticklabels =3)\n",
    "ax.set_yticklabels([labels[str(i)] for i in dft.index], rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.autofmt_xdate()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure A3\n",
    "\n",
    "```python\n",
    "from src.fui.cluster import ClusterTree\n",
    "\n",
    "cl90 = ClusterTree(90,metric='cosine')\n",
    "\n",
    "# Cluster labels added manually\n",
    "fig, ax, R = cl90.dendrogram(colors=12, annotate=False)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
